{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "diabetes_dataset = pd.read_csv('diabetic_data.csv')\n",
    "diabetes_dataset.drop(axis=1, columns=['weight', 'medical_specialty', 'payer_code'], inplace=True)\n",
    "diabetes_dataset = diabetes_dataset.sort_values(by=['patient_nbr', 'encounter_id'])\n",
    "# Define the ranges and replacement values\n",
    "ICD9_mapping = [\n",
    "    ((1, 139), 'Infectious And Parasitic Diseases'),\n",
    "    ((140, 239), 'Neoplasms'),\n",
    "    ((240, 279), 'Endocrine, Nutritional And Metabolic Diseases, And Immunity Disorders'),\n",
    "    ((280, 289), 'Diseases Of The Blood And Blood-Forming Organs'), \n",
    "    ((290, 319), 'Mental Disorders'),\n",
    "    ((320, 389), 'Diseases Of The Nervous System And Sense Organs'),\n",
    "    ((390, 459), 'Diseases Of The Circulatory System'), \n",
    "    ((460, 519), 'Diseases Of The Respiratory System'),\n",
    "    ((520, 579), 'Diseases Of The Digestive System'),\n",
    "    ((580, 629), 'Diseases Of The Genitourinary System'), \n",
    "    ((630, 679), 'Complications Of Pregnancy, Childbirth, And The Puerperium'),\n",
    "    ((680, 709), 'Diseases Of The Skin And Subcutaneous Tissue'),\n",
    "    ((710, 739), 'Diseases Of The Musculoskeletal System And Connective Tissue'),\n",
    "    ((740, 759), 'Congenital Anomalies'), \n",
    "    ((760, 779), 'Certain Conditions Originating In The Perinatal Period'),\n",
    "    ((780, 799), 'Symptoms, Signs, And Ill-Defined Conditions'),\n",
    "    ((800, 999), 'Injury And Poisoning'),\n",
    "    ('V', 'Supplementary Classification Of Factors Influencing Health Status And Contact With Health Services'),\n",
    "    ('E', 'Supplementary Classification Of External Causes Of Injury And Poisoning')\n",
    "]\n",
    "\n",
    "# Custom function to replace values based on multiple ranges\n",
    "def replace_multiple_ranges(x, ranges_and_values):\n",
    "    for values, new_value in ranges_and_values:\n",
    "        if type(values) == tuple and x[0] != 'V' and x[0] != 'E' and x != '?':\n",
    "            if values[0] <= int(float(x)) <= values[1]:\n",
    "                return new_value\n",
    "        elif type(values) == str and x[0] == values:\n",
    "            return new_value\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom function to the diagnosis columns\n",
    "diabetes_dataset['diag_1'] = diabetes_dataset['diag_1'].apply(replace_multiple_ranges, args=(ICD9_mapping,))\n",
    "diabetes_dataset['diag_2'] = diabetes_dataset['diag_2'].apply(replace_multiple_ranges, args=(ICD9_mapping,))\n",
    "diabetes_dataset['diag_3'] = diabetes_dataset['diag_3'].apply(replace_multiple_ranges, args=(ICD9_mapping,))\n",
    "\n",
    "# Replace '?' with 'no record' across diag_2 and diag_3\n",
    "diabetes_dataset[['diag_2', 'diag_3']] = diabetes_dataset[['diag_2', 'diag_3']].replace('?', 'no record')\n",
    "\n",
    "# Replace '?' with NaN\n",
    "diabetes_dataset[['race', 'diag_1']] = diabetes_dataset[['race', 'diag_1']].replace('?', np.nan)\n",
    "\n",
    "# Drop rows with missing values in columns 'race' and 'diag_1'\n",
    "diabetes_dataset.dropna(subset=['race', 'diag_1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_type_id_mapping = {1:'Emergency',\n",
    "                             2:'Urgent',\n",
    "                             3:'Elective',\n",
    "                             4:'Newborn',\n",
    "                             5:'Not Available',\n",
    "                             6:'NULL',\n",
    "                             7:'Trauma Center',\n",
    "                             8:'Not Mapped'\n",
    "                            }\n",
    "\n",
    "discharge_disposition_id_mapping = {1: 'ischarged to home',\n",
    "                                    2:'ischarged/transferred to another short term hospital',\n",
    "                                    3:'ischarged/transferred to SNF',\n",
    "                                    4:'ischarged/transferred to ICF',\n",
    "                                    5:'ischarged/transferred to another type of inpatient care institution',\n",
    "                                    6:'ischarged/transferred to home with home health service',\n",
    "                                    7:'eft AMA',\n",
    "                                    8:'ischarged/transferred to home under care of Home IV provider',\n",
    "                                    9:'dmitted as an inpatient to this hospital',\n",
    "                                    10:'Neonate discharged to another hospital for neonatal aftercare',\n",
    "                                    11:'Expired',\n",
    "                                    12:'Still patient or expected to return for outpatient services',\n",
    "                                    13:'Hospice / home',\n",
    "                                    14:'Hospice / medical facility',\n",
    "                                    15:'Discharged/transferred within this institution to Medicare approved swing bed',\n",
    "                                    16:'Discharged/transferred/referred another institution for outpatient services',\n",
    "                                    17:'Discharged/transferred/referred to this institution for outpatient services',\n",
    "                                    18:'NULL',\n",
    "                                    19:'Expired at home. Medicaid only, hospice.',\n",
    "                                    20:'Expired in a medical facility. Medicaid only, hospice.',\n",
    "                                    21:'Expired, place unknown. Medicaid only, hospice.',\n",
    "                                    22:'Discharged/transferred to another rehab fac including rehab units of a hospital.',\n",
    "                                    23:'Discharged/transferred to a long term care hospital.',\n",
    "                                    24:'Discharged/transferred to a nursing facility certified under Medicaid but not certified under Medicare.',\n",
    "                                    25:'Not Mapped',\n",
    "                                    26:'Unknown/Invalid',\n",
    "                                    30:'Discharged/transferred to another Type of Health Care Institution not Defined Elsewhere',\n",
    "                                    27:'Discharged/transferred to a federal health care facility.',\n",
    "                                    28:'Discharged/transferred/referred to a psychiatric hospital of psychiatric distinct part unit of a hospital',\n",
    "                                    29:'Discharged/transferred to a Critical Access Hospital (CAH).'\n",
    "                                    }\n",
    "\n",
    "admission_source_id_mapping = {1: 'Physician Referral',\n",
    "                               2: 'Clinic Referral',\n",
    "                               3: 'HMO Referral',\n",
    "                               4: 'Transfer from a hospital',\n",
    "                               5: 'Transfer from a Skilled Nursing Facility (SNF)',\n",
    "                               6: 'Transfer from another health care facility',\n",
    "                               7: 'Emergency Room',\n",
    "                               8: 'Court/Law Enforcement',\n",
    "                               9: 'Not Available',\n",
    "                               10:' Transfer from critial access hospital',\n",
    "                               11:' Normal Delivery',\n",
    "                               12:' Premature Delivery',\n",
    "                               13:' Sick Baby',\n",
    "                               14:' Extramural Birth',\n",
    "                               15:' Not Available',\n",
    "                               17:' NULL',\n",
    "                               18:' Transfer From Another Home Health Agency',\n",
    "                               19:' Readmission to Same Home Health Agency',\n",
    "                               20:' Not Mapped',\n",
    "                               21:' Unknown/Invalid',\n",
    "                               22:' Transfer from hospital inpt/same fac reslt in a sep claim',\n",
    "                               23:' Born inside this hospital',\n",
    "                               24:' Born outside this hospital',\n",
    "                               25:' Transfer from Ambulatory Surgery Center',\n",
    "                               26:' Transfer from Hospice'\n",
    "                               }\n",
    "\n",
    "diabetes_dataset['admission_type_id'] = diabetes_dataset['admission_type_id'].replace(admission_type_id_mapping)\n",
    "diabetes_dataset['discharge_disposition_id'] = diabetes_dataset['discharge_disposition_id'].replace(discharge_disposition_id_mapping)\n",
    "diabetes_dataset['admission_source_id'] = diabetes_dataset['admission_source_id'].replace(admission_source_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate differences between consecutive rows\n",
    "def calculate_differences(diabetes_dataset, idx1, idx2):\n",
    "    differences = {}\n",
    "    for column in diabetes_dataset.columns:\n",
    "        if column != 'readmitted':\n",
    "            if pd.api.types.is_numeric_dtype(diabetes_dataset[column]):\n",
    "                differences[column] = diabetes_dataset.at[idx1, column] - diabetes_dataset.at[idx2, column]\n",
    "            else:\n",
    "                differences[column] = 1 if diabetes_dataset.at[idx1, column] != diabetes_dataset.at[idx2, column] else 0\n",
    "    return differences\n",
    "\n",
    "# Function to identify shifts and calculate differences within a group\n",
    "def process_group(group):\n",
    "    shifts = ((group['readmitted'] == '<30') & ((group['readmitted'].shift(1) == 'NO') | (group['readmitted'].shift(1) == '>30')))\n",
    "    shift_indices = group.index[shifts]\n",
    "    \n",
    "\n",
    "    differences_list = []\n",
    "    for idx in shift_indices:\n",
    "        if idx > group.index.min():\n",
    "            prev_idx = group.index[group.index.get_loc(idx) - 1]  # Safely get the previous index\n",
    "            differences = calculate_differences(group, prev_idx, idx)\n",
    "            differences_list.append(differences)\n",
    "    \n",
    "    return differences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each group and collect all differences\n",
    "all_differences = []\n",
    "for patient_id, group in diabetes_dataset.groupby('patient_nbr'):\n",
    "    all_differences.extend(process_group(group))\n",
    "\n",
    "# Convert list of differences to a DataFrame\n",
    "differences_diabetes_dataset = pd.DataFrame(all_differences)\n",
    "\n",
    "# Calculate the mean differences (normalize by the number of shifts)\n",
    "normalized_differences = differences_diabetes_dataset.abs().mean()\n",
    "\n",
    "# Get feature names with normalized difference value below 0.01\n",
    "features_below_threshold = normalized_differences[normalized_differences < 0.01].index.tolist()\n",
    "\n",
    "\n",
    "# Ensure the column to keep is not in the columns to drop\n",
    "columns_to_drop = [col for col in features_below_threshold if col != 'patient_nbr']\n",
    "\n",
    "diabetes_dataset_important_features = diabetes_dataset.drop(columns_to_drop, axis=1)\n",
    "diabetes_dataset_important_features.drop(['encounter_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_encode(df):\n",
    "    # select all categorical columns\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "\n",
    "    # Convert string columns to categorical\n",
    "    for col in categorical_columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "        df[col] = df[col].cat.codes.astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the unique identifier column\n",
    "def load_data(df):\n",
    "\n",
    "    # encode dataframe first\n",
    "    sparse_encode(df)\n",
    "    \n",
    "    unique_id_column = 'patient_nbr'\n",
    "\n",
    "    # Split into training and remaining sets (validation + test)\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n",
    "    train_idx, remaining_idx = next(splitter.split(df, groups=df[unique_id_column]))\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[remaining_idx]\n",
    "\n",
    "    # Split remaining set into validation and test sets\n",
    "    #splitter = GroupShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "    #val_idx, test_idx = next(splitter.split(remaining_df, groups=remaining_df[unique_id_column]))\n",
    "\n",
    "    #val_df = remaining_df.iloc[val_idx]\n",
    "    #test_df = remaining_df.iloc[test_idx]\n",
    "\n",
    "    # remove patient number after use for splitting\n",
    "    train_df, test_df = train_df.drop(['patient_nbr'], axis=1), test_df.drop(['patient_nbr'], axis=1)\n",
    "\n",
    "    train_y = train_df['readmitted']\n",
    "    train_df.drop(['readmitted'], axis=1, inplace=True)\n",
    "    train_x = train_df\n",
    "\n",
    "    test_y = test_df['readmitted']\n",
    "    test_df.drop(['readmitted'], axis=1, inplace=True)\n",
    "    test_x = test_df\n",
    "\n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfiltered loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       race gender age admission_type_id discharge_disposition_id  \\\n",
      "5827      2      0   5                 0                       19   \n",
      "67608     2      0   8                 1                       21   \n",
      "1164      0      0   5                 1                       19   \n",
      "5953      0      0   5                 1                       19   \n",
      "14180     0      0   6                 1                       19   \n",
      "...     ...    ...  ..               ...                      ...   \n",
      "95283     1      0   7                 1                       19   \n",
      "95282     4      1   6                 1                       19   \n",
      "93651     2      0   8                 1                       19   \n",
      "101748    2      0   4                 1                       20   \n",
      "96147     2      1   4                 7                       19   \n",
      "\n",
      "       admission_source_id  time_in_hospital  num_lab_procedures  \\\n",
      "5827                    13                 2                  49   \n",
      "67608                   10                 4                  68   \n",
      "1164                    10                 6                  43   \n",
      "5953                    10                 6                  45   \n",
      "14180                   10                10                  54   \n",
      "...                    ...               ...                 ...   \n",
      "95283                   10                 1                  31   \n",
      "95282                   10                 3                  56   \n",
      "93651                   10                 3                  39   \n",
      "101748                  10                14                  69   \n",
      "96147                   13                 5                  35   \n",
      "\n",
      "        num_procedures  num_medications  ...  examide  citoglipton  insulin  \\\n",
      "5827                 1               11  ...        0            0        1   \n",
      "67608                2               23  ...        0            0        1   \n",
      "1164                 2               13  ...        0            0        2   \n",
      "5953                 4               15  ...        0            0        0   \n",
      "14180                2               19  ...        0            0        2   \n",
      "...                ...              ...  ...      ...          ...      ...   \n",
      "95283                0                6  ...        0            0        1   \n",
      "95282                1                8  ...        0            0        2   \n",
      "93651                0               18  ...        0            0        0   \n",
      "101748               0               16  ...        0            0        0   \n",
      "96147                4               23  ...        0            0        3   \n",
      "\n",
      "       glyburide-metformin glipizide-metformin glimepiride-pioglitazone  \\\n",
      "5827                     1                   0                        0   \n",
      "67608                    1                   0                        0   \n",
      "1164                     1                   0                        0   \n",
      "5953                     1                   0                        0   \n",
      "14180                    1                   0                        0   \n",
      "...                    ...                 ...                      ...   \n",
      "95283                    1                   0                        0   \n",
      "95282                    1                   0                        0   \n",
      "93651                    1                   0                        0   \n",
      "101748                   1                   0                        0   \n",
      "96147                    1                   0                        0   \n",
      "\n",
      "        metformin-rosiglitazone metformin-pioglitazone change diabetesMed  \n",
      "5827                          0                      0      1           0  \n",
      "67608                         0                      0      1           1  \n",
      "1164                          0                      0      1           1  \n",
      "5953                          0                      0      0           1  \n",
      "14180                         0                      0      1           1  \n",
      "...                         ...                    ...    ...         ...  \n",
      "95283                         0                      0      1           1  \n",
      "95282                         0                      0      1           1  \n",
      "93651                         0                      0      0           1  \n",
      "101748                        0                      0      0           1  \n",
      "96147                         0                      0      0           1  \n",
      "\n",
      "[59556 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "#diabetes_dataset = diabetes_dataset.drop(['encounter_id'], axis=1)\n",
    "\n",
    "train_features, train_labels, test_features, test_labels = load_data(diabetes_dataset)\n",
    "print(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age admission_type_id discharge_disposition_id admission_source_id  \\\n",
      "5827     5                 0                       19                  13   \n",
      "67608    8                 1                       21                  10   \n",
      "1164     5                 1                       19                  10   \n",
      "5953     5                 1                       19                  10   \n",
      "14180    6                 1                       19                  10   \n",
      "...     ..               ...                      ...                 ...   \n",
      "95283    7                 1                       19                  10   \n",
      "95282    6                 1                       19                  10   \n",
      "93651    8                 1                       19                  10   \n",
      "101748   4                 1                       20                  10   \n",
      "96147    4                 7                       19                  13   \n",
      "\n",
      "        time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
      "5827                   2                  49               1               11   \n",
      "67608                  4                  68               2               23   \n",
      "1164                   6                  43               2               13   \n",
      "5953                   6                  45               4               15   \n",
      "14180                 10                  54               2               19   \n",
      "...                  ...                 ...             ...              ...   \n",
      "95283                  1                  31               0                6   \n",
      "95282                  3                  56               1                8   \n",
      "93651                  3                  39               0               18   \n",
      "101748                14                  69               0               16   \n",
      "96147                  5                  35               4               23   \n",
      "\n",
      "        number_outpatient  number_emergency  ...  metformin repaglinide  \\\n",
      "5827                    0                 0  ...          1           1   \n",
      "67608                   0                 0  ...          2           1   \n",
      "1164                    0                 0  ...          1           1   \n",
      "5953                    0                 0  ...          1           1   \n",
      "14180                   0                 0  ...          1           1   \n",
      "...                   ...               ...  ...        ...         ...   \n",
      "95283                   0                 0  ...          1           1   \n",
      "95282                   0                 0  ...          1           1   \n",
      "93651                   0                 0  ...          2           1   \n",
      "101748                  0                 0  ...          3           1   \n",
      "96147                   0                 0  ...          1           1   \n",
      "\n",
      "       glimepiride glipizide  glyburide pioglitazone rosiglitazone insulin  \\\n",
      "5827             1         1          1            1             1       1   \n",
      "67608            1         1          1            1             1       1   \n",
      "1164             1         1          1            1             1       2   \n",
      "5953             1         1          1            1             1       0   \n",
      "14180            1         1          1            1             1       2   \n",
      "...            ...       ...        ...          ...           ...     ...   \n",
      "95283            2         1          1            1             1       1   \n",
      "95282            1         1          1            1             1       2   \n",
      "93651            1         3          1            1             2       0   \n",
      "101748           1         1          2            1             1       0   \n",
      "96147            1         1          1            1             1       3   \n",
      "\n",
      "       change diabetesMed  \n",
      "5827        1           0  \n",
      "67608       1           1  \n",
      "1164        1           1  \n",
      "5953        0           1  \n",
      "14180       1           1  \n",
      "...       ...         ...  \n",
      "95283       1           1  \n",
      "95282       1           1  \n",
      "93651       0           1  \n",
      "101748      0           1  \n",
      "96147       0           1  \n",
      "\n",
      "[59556 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "filtered_train_features, filtered_train_labels, filtered_test_features, filtered_test_labels = load_data(diabetes_dataset_important_features)\n",
    "\n",
    "print(filtered_train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RuleFit (RQ1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/christophM/rulefit.git\n",
      "  Cloning https://github.com/christophM/rulefit.git to c:\\users\\taher\\appdata\\local\\temp\\pip-req-build-79um5939\n",
      "  Resolved https://github.com/christophM/rulefit.git to commit 472b8574b4eb9e565caf1e05ed580998fe2c9a8e\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn>=0.20.2 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from RuleFit==0.3) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.16.1 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from RuleFit==0.3) (1.24.0)\n",
      "Requirement already satisfied: pandas>=0.24.1 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from RuleFit==0.3) (2.1.4)\n",
      "Collecting ordered-set>=4.1.0 (from RuleFit==0.3)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24.1->RuleFit==0.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24.1->RuleFit==0.3) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=0.24.1->RuleFit==0.3) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20.2->RuleFit==0.3) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20.2->RuleFit==0.3) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20.2->RuleFit==0.3) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\taher\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.1->RuleFit==0.3) (1.16.0)\n",
      "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: RuleFit\n",
      "  Building wheel for RuleFit (setup.py): started\n",
      "  Building wheel for RuleFit (setup.py): finished with status 'done'\n",
      "  Created wheel for RuleFit: filename=RuleFit-0.3-py3-none-any.whl size=8152 sha256=c3b41e589b809d34366002a668fec9150939baabaa3863551e541de8c9230230\n",
      "  Stored in directory: C:\\Users\\Taher\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-cdd2w3wn\\wheels\\b0\\96\\20\\f12d41437ad659039df4712cafbea67964fc36056ddbbbd7c2\n",
      "Successfully built RuleFit\n",
      "Installing collected packages: ordered-set, RuleFit\n",
      "Successfully installed RuleFit-0.3 ordered-set-4.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/christophM/rulefit.git 'C:\\Users\\Taher\\AppData\\Local\\Temp\\pip-req-build-79um5939'\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/christophM/rulefit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 10)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrulefit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RuleFit\n\u001b[0;32m      3\u001b[0m rf \u001b[38;5;241m=\u001b[39m RuleFit()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rulefit\\rulefit.py:494\u001b[0m, in \u001b[0;36mRuleFit.fit\u001b[1;34m(self, X, y, feature_names)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrule_ensemble \u001b[38;5;241m=\u001b[39m RuleEnsemble(\n\u001b[0;32m    490\u001b[0m         tree_list\u001b[38;5;241m=\u001b[39mtree_list, feature_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names\n\u001b[0;32m    491\u001b[0m     )\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;66;03m## concatenate original features and rules\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m     X_rules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrule_ensemble\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;66;03m## standardise linear variables if requested (for regression model only)\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;66;03m## standard deviation and mean of winsorized features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rulefit\\rulefit.py:289\u001b[0m, in \u001b[0;36mRuleEnsemble.transform\u001b[1;34m(self, X, coefs)\u001b[0m\n\u001b[0;32m    287\u001b[0m rule_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrules)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coefs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mrule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrule\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrule_list\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# else use the coefs to filter the rules we bother to interpret\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m    292\u001b[0m         [\n\u001b[0;32m    293\u001b[0m             rule_list[i_rule]\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         ]\n\u001b[0;32m    297\u001b[0m     )\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rulefit\\rulefit.py:289\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    287\u001b[0m rule_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrules)\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coefs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mrule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m rule \u001b[38;5;129;01min\u001b[39;00m rule_list])\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# else use the coefs to filter the rules we bother to interpret\u001b[39;00m\n\u001b[0;32m    291\u001b[0m     res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m    292\u001b[0m         [\n\u001b[0;32m    293\u001b[0m             rule_list[i_rule]\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         ]\n\u001b[0;32m    297\u001b[0m     )\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rulefit\\rulefit.py:169\u001b[0m, in \u001b[0;36mRule.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform dataset.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    X_transformed: array-like matrix, shape=(n_samples, 1)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     rule_applies \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditions\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduce(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x \u001b[38;5;241m*\u001b[39m y, rule_applies)\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rulefit\\rulefit.py:169\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform dataset.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    X_transformed: array-like matrix, shape=(n_samples, 1)\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m     rule_applies \u001b[38;5;241m=\u001b[39m [\u001b[43mcondition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m condition \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconditions]\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduce(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x \u001b[38;5;241m*\u001b[39m y, rule_applies)\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\rulefit\\rulefit.py:63\u001b[0m, in \u001b[0;36mRuleCondition.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform dataset.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mX_transformed: array-like matrix, shape=(n_samples, 1)\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperator \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<=\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_index\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperator \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     65\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m (X[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_index] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold)\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3803\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Taher\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5975\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5972\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5973\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5974\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5975\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 10)"
     ]
    }
   ],
   "source": [
    "from rulefit import RuleFit\n",
    "\n",
    "rf = RuleFit()\n",
    "rf.fit(filtered_train_features, filtered_train_labels, feature_names=filtered_train_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(filtered_test_labels)\n",
    "\n",
    "rules = rf.get_rules()\n",
    "\n",
    "rules = rules[rules.coef != 0].sort_values(\"support\", ascending=False)\n",
    "\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EBM (RQ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aukevanderkuil/anaconda3/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:738: UserWarning: Missing values detected. Our visualizations do not currently display missing values. To retain the glassbox nature of the model you need to either set the missing values to an extreme value like -1000 that will be visible on the graphs, or manually examine the missing value score in ebm.term_scores_[term_index][0]\n",
      "  warn(\n",
      "/Users/aukevanderkuil/anaconda3/lib/python3.11/site-packages/interpret/glassbox/_ebm/_ebm.py:995: UserWarning: Detected multiclass problem. Forcing interactions to 0. Multiclass interactions only have local explanations. They are not currently displayed in the global explanation visualizations. Set interactions=0 to disable this warning. If you still want multiclass interactions, this API accepts a list, and the measure_interactions function can be used to detect them.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <30       0.42      0.03      0.06      1712\n",
      "         >30       0.52      0.40      0.45      5295\n",
      "          NO       0.62      0.84      0.72      7984\n",
      "\n",
      "    accuracy                           0.59     14991\n",
      "   macro avg       0.52      0.42      0.41     14991\n",
      "weighted avg       0.56      0.59      0.55     14991\n",
      "\n",
      "Feature: patient_nbr, Importance: 0.11223404498774284\n",
      "Feature: age, Importance: 0.02407453065017418\n",
      "Feature: admission_type_id, Importance: 0.026268147528861915\n",
      "Feature: discharge_disposition_id, Importance: 0.12106711146551458\n",
      "Feature: admission_source_id, Importance: 0.03213583651692902\n",
      "Feature: time_in_hospital, Importance: 0.03650029557344752\n",
      "Feature: num_lab_procedures, Importance: 0.01988954845956776\n",
      "Feature: num_procedures, Importance: 0.02861078847254449\n",
      "Feature: num_medications, Importance: 0.03133218029812399\n",
      "Feature: number_outpatient, Importance: 0.02562458578136073\n",
      "Feature: number_emergency, Importance: 0.03328733253845422\n",
      "Feature: number_inpatient, Importance: 0.16841701616831017\n",
      "Feature: diag_1, Importance: 0.039849587307244215\n",
      "Feature: diag_2, Importance: 0.025641521271808673\n",
      "Feature: diag_3, Importance: 0.018628097300038744\n",
      "Feature: number_diagnoses, Importance: 0.04103027370897157\n",
      "Feature: max_glu_serum, Importance: 0.00998704191885781\n",
      "Feature: A1Cresult, Importance: 0.01974284183561801\n",
      "Feature: metformin, Importance: 0.027033676453008554\n",
      "Feature: repaglinide, Importance: 0.0012637857415528004\n",
      "Feature: glimepiride, Importance: 0.005132400680822653\n",
      "Feature: glipizide, Importance: 0.005367058532468496\n",
      "Feature: glyburide, Importance: 0.004425250116663989\n",
      "Feature: pioglitazone, Importance: 0.007076860226212112\n",
      "Feature: rosiglitazone, Importance: 0.007326030805077669\n",
      "Feature: insulin, Importance: 0.02337509377164065\n",
      "Feature: change, Importance: 0.009979513126078185\n",
      "Feature: diabetesMed, Importance: 0.04266904251792654\n",
      "                     Feature  Importance\n",
      "11          number_inpatient    0.168417\n",
      "3   discharge_disposition_id    0.121067\n",
      "0                patient_nbr    0.112234\n",
      "27               diabetesMed    0.042669\n",
      "15          number_diagnoses    0.041030\n",
      "12                    diag_1    0.039850\n",
      "5           time_in_hospital    0.036500\n",
      "10          number_emergency    0.033287\n",
      "4        admission_source_id    0.032136\n",
      "8            num_medications    0.031332\n"
     ]
    }
   ],
   "source": [
    "## Research Question 2: intrinsic Global Explanations\n",
    "# Import necessary libraries\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def load_data(dataset, train_size=0.7, val_size=0.15, test_size=0.15, random_state=42):\n",
    "    # Ensure the proportions sum to 1.0\n",
    "    assert train_size + val_size + test_size == 1.0, \"Train, validation, and test sizes must sum to 1.0\"\n",
    "    \n",
    "    # Split unique patient numbers into train, validation, and test sets\n",
    "    unique_patients = dataset['patient_nbr'].unique()\n",
    "    train_patients, remaining_patients = train_test_split(unique_patients, train_size=train_size, random_state=random_state)\n",
    "    val_proportion = val_size / (val_size + test_size)\n",
    "    val_patients, test_patients = train_test_split(remaining_patients, train_size=val_proportion, random_state=random_state)\n",
    "    \n",
    "    # Select records based on the patient splits\n",
    "    train_set = dataset[dataset['patient_nbr'].isin(train_patients)]\n",
    "    val_set = dataset[dataset['patient_nbr'].isin(val_patients)]\n",
    "    test_set = dataset[dataset['patient_nbr'].isin(test_patients)]\n",
    "    \n",
    "    # Split features and labels\n",
    "    def split_feature_label(data_set):\n",
    "        features = data_set.drop(columns=['readmitted'])\n",
    "        labels = data_set['readmitted']\n",
    "        return features, labels\n",
    "\n",
    "    train_features, train_labels = split_feature_label(train_set)\n",
    "    val_features, val_labels = split_feature_label(val_set)\n",
    "    test_features, test_labels = split_feature_label(test_set)\n",
    "\n",
    "    return train_features, train_labels, val_features, val_labels, test_features, test_labels\n",
    "\n",
    "# Load the data\n",
    "(train_features, train_labels, val_features, val_labels, test_features, test_labels) = load_data(diabetes_dataset_important_features)\n",
    "\n",
    "# Train the EBM model\n",
    "ebm = ExplainableBoostingClassifier(random_state=42)\n",
    "ebm.fit(train_features, train_labels)\n",
    "\n",
    "# Validate the model\n",
    "val_predictions = ebm.predict(val_features)\n",
    "print(classification_report(val_labels, val_predictions))\n",
    "\n",
    "# Extract the most important features\n",
    "feature_importances = ebm.explain_global().data()\n",
    "\n",
    "# Print the feature importances\n",
    "for feature in feature_importances['names']:\n",
    "    importance = feature_importances['scores'][feature_importances['names'].index(feature)]\n",
    "    print(f'Feature: {feature}, Importance: {importance}')\n",
    "\n",
    "# Create a DataFrame\n",
    "importances_df = pd.DataFrame({'Feature': feature_importances['names'], 'Importance': feature_importances['scores']})\n",
    "importances_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Display the top 10 most important features\n",
    "print(importances_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
